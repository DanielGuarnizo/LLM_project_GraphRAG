{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca53a973",
   "metadata": {},
   "source": [
    "#### Needed setup variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67eaf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09caf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879f2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_db_name = \"t20\"\n",
    "# kg_db_name = \"t30documentsgraph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6dd16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_9191/2508706621.py:1: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  kg = Neo4jGraph(\n"
     ]
    }
   ],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, \n",
    "    username=NEO4J_USERNAME, \n",
    "    password=NEO4J_PASSWORD, \n",
    "    database=kg_db_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbd14e",
   "metadata": {},
   "source": [
    "#### Detect Hierarchical communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f352bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hierarchical_community_detector import HierarchicalCommunityDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f2730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_community_detector = HierarchicalCommunityDetector(\n",
    "    kg=kg,\n",
    "    kg_db_name=kg_db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc16c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂ Creating base projection from KG...\n",
      "\n",
      "  Skipping Leiden on t20_projection: C3_CommunityId already exists.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 6...\n",
      "‚úÖ Community Summary already esist for Community 6\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 7...\n",
      "‚úÖ Community Summary already esist for Community 7\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 42...\n",
      "‚úÖ Community Summary already esist for Community 42\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 64...\n",
      "‚úÖ Community Summary already esist for Community 64\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 14...\n",
      "‚úÖ Community Summary already esist for Community 14\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 15...\n",
      "‚úÖ Community Summary already esist for Community 15\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 62...\n",
      "‚úÖ Community Summary already esist for Community 62\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 4...\n",
      "‚úÖ Community Summary already esist for Community 4\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 70...\n",
      "‚úÖ Community Summary already esist for Community 70\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 1...\n",
      "‚úÖ Community Summary already esist for Community 1\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 21...\n",
      "‚úÖ Community Summary already esist for Community 21\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 18...\n",
      "‚úÖ Community Summary already esist for Community 18\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 0...\n",
      "‚úÖ Community Summary already esist for Community 0\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 9...\n",
      "‚úÖ Community Summary already esist for Community 9\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 22...\n",
      "‚úÖ Community Summary already esist for Community 22\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 16...\n",
      "‚úÖ Community Summary already esist for Community 16\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 17...\n",
      "‚úÖ Community Summary already esist for Community 17\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 2...\n",
      "‚úÖ Community Summary already esist for Community 2\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 37...\n",
      "‚úÖ Community Summary already esist for Community 37\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 39...\n",
      "‚úÖ Community Summary already esist for Community 39\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 60...\n",
      "‚úÖ Community Summary already esist for Community 60\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 48...\n",
      "‚úÖ Community Summary already esist for Community 48\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 5...\n",
      "‚úÖ Community Summary already esist for Community 5\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 10...\n",
      "‚úÖ Community Summary already esist for Community 10\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 79...\n",
      "‚úÖ Community Summary already esist for Community 79\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 20...\n",
      "‚úÖ Community Summary already esist for Community 20\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 44...\n",
      "‚úÖ Community Summary already esist for Community 44\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 49...\n",
      "‚úÖ Community Summary already esist for Community 49\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 71...\n",
      "‚úÖ Community Summary already esist for Community 71\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 65...\n",
      "‚úÖ Community Summary already esist for Community 65\n",
      "[]\n",
      "‚ö†Ô∏è No community IDs to remove.\n",
      "\n",
      "‚ñ∂ Creating projection from graph name: C3_graph\n",
      "\n",
      "  Skipping Leiden on C3_graph: C2_CommunityId already exists.\n",
      "\n",
      "‚ñ∂ Creating community nodes and edges for level C2\n",
      "\n",
      "‚ö†Ô∏è Skipping C1 level: C2_graph has no relationships.\n"
     ]
    }
   ],
   "source": [
    "hierarchical_community_detector.detect_hierarchical_communities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0a64a",
   "metadata": {},
   "source": [
    "#### Test Community detection for different level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4dfeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hierarchical_community_detector import HierarchicalCommunityDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fe0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HierarchicalCommunityDetector(kg=kg, kg_db_name=kg_db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9385567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂ Base graph 't20_projection' already projected.\n",
      "\n",
      "  Skipping Leiden on t20_projection: C3_CommunityId already exists.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 6...\n",
      "‚úÖ Community Summary already esist for Community 6\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 7...\n",
      "‚úÖ Community Summary already esist for Community 7\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 42...\n",
      "‚úÖ Community Summary already esist for Community 42\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 64...\n",
      "‚úÖ Community Summary already esist for Community 64\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 14...\n",
      "‚úÖ Community Summary already esist for Community 14\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 15...\n",
      "‚úÖ Community Summary already esist for Community 15\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 62...\n",
      "‚úÖ Community Summary already esist for Community 62\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 4...\n",
      "‚úÖ Community Summary already esist for Community 4\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 70...\n",
      "‚úÖ Community Summary already esist for Community 70\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 1...\n",
      "‚úÖ Community Summary already esist for Community 1\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 21...\n",
      "‚úÖ Community Summary already esist for Community 21\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 18...\n",
      "‚úÖ Community Summary already esist for Community 18\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 0...\n",
      "‚úÖ Community Summary already esist for Community 0\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 9...\n",
      "‚úÖ Community Summary already esist for Community 9\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 22...\n",
      "‚úÖ Community Summary already esist for Community 22\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 16...\n",
      "‚úÖ Community Summary already esist for Community 16\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 17...\n",
      "‚úÖ Community Summary already esist for Community 17\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 2...\n",
      "‚úÖ Community Summary already esist for Community 2\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 37...\n",
      "‚úÖ Community Summary already esist for Community 37\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 39...\n",
      "‚úÖ Community Summary already esist for Community 39\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 60...\n",
      "‚úÖ Community Summary already esist for Community 60\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 48...\n",
      "‚úÖ Community Summary already esist for Community 48\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 5...\n",
      "‚úÖ Community Summary already esist for Community 5\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 10...\n",
      "‚úÖ Community Summary already esist for Community 10\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 79...\n",
      "‚úÖ Community Summary already esist for Community 79\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 20...\n",
      "‚úÖ Community Summary already esist for Community 20\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 44...\n",
      "‚úÖ Community Summary already esist for Community 44\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 49...\n",
      "‚úÖ Community Summary already esist for Community 49\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 71...\n",
      "‚úÖ Community Summary already esist for Community 71\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 65...\n",
      "‚úÖ Community Summary already esist for Community 65\n",
      "[]\n",
      "‚ö†Ô∏è No community IDs to remove.\n",
      "\n",
      "‚ñ∂ Graph 'C3_graph' already projected.\n",
      "\n",
      "  Skipping Leiden on C3_graph: C2_CommunityId already exists.\n",
      "\n",
      "‚ö†Ô∏è Skipping C1 level: C2_graph has no relationships.\n"
     ]
    }
   ],
   "source": [
    "detector.detect_hierarchical_communities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba1de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking available community levels...\n",
      "‚úÖ C2 Level: Yes\n",
      "‚úÖ C1 Level: No\n",
      "‚úÖ C0 Level: No\n",
      "[{'C2_CommunityId': 14, 'children': [6]}, {'C2_CommunityId': 27, 'children': [7, 64, 0, 2]}, {'C2_CommunityId': 13, 'children': [42]}, {'C2_CommunityId': 8, 'children': [14]}, {'C2_CommunityId': 11, 'children': [15]}, {'C2_CommunityId': 10, 'children': [62]}, {'C2_CommunityId': 19, 'children': [4]}, {'C2_CommunityId': 18, 'children': [70]}, {'C2_CommunityId': 21, 'children': [1]}, {'C2_CommunityId': 20, 'children': [21]}, {'C2_CommunityId': 17, 'children': [18]}, {'C2_CommunityId': 15, 'children': [9]}, {'C2_CommunityId': 16, 'children': [22]}, {'C2_CommunityId': 28, 'children': [16]}, {'C2_CommunityId': 26, 'children': [17]}, {'C2_CommunityId': 23, 'children': [37]}, {'C2_CommunityId': 22, 'children': [39]}, {'C2_CommunityId': 25, 'children': [60]}, {'C2_CommunityId': 24, 'children': [48]}, {'C2_CommunityId': 7, 'children': [5]}, {'C2_CommunityId': 6, 'children': [10]}, {'C2_CommunityId': 4, 'children': [79]}, {'C2_CommunityId': 5, 'children': [20]}, {'C2_CommunityId': 1, 'children': [44]}, {'C2_CommunityId': 0, 'children': [49]}, {'C2_CommunityId': 3, 'children': [71]}, {'C2_CommunityId': 2, 'children': [65]}]\n"
     ]
    }
   ],
   "source": [
    "hierarchycal_structure = detector.build_community_hierarchy_flexible()\n",
    "print(hierarchycal_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de73081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(hierarchycal_structure))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a7cc4",
   "metadata": {},
   "source": [
    "### Test CommunitySummaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.leaf_level_community_summaries import create_leaf_level_community_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b8b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂ Summarizing C3 Community 6...\n",
      "‚úÖ Community Summary already esist for Community 6\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 7...\n",
      "‚úÖ Community Summary already esist for Community 7\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 42...\n",
      "‚úÖ Community Summary already esist for Community 42\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 64...\n",
      "‚úÖ Community Summary already esist for Community 64\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 55...\n",
      "‚ö†Ô∏è Skipping Community 55: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 52...\n",
      "‚ö†Ô∏è Skipping Community 52: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 13...\n",
      "‚ö†Ô∏è Skipping Community 13: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 14...\n",
      "‚úÖ Community Summary already esist for Community 14\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 15...\n",
      "‚úÖ Community Summary already esist for Community 15\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 62...\n",
      "‚úÖ Community Summary already esist for Community 62\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 4...\n",
      "‚úÖ Community Summary already esist for Community 4\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 70...\n",
      "‚úÖ Community Summary already esist for Community 70\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 40...\n",
      "‚ö†Ô∏è Skipping Community 40: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 1...\n",
      "‚úÖ Saved structured summary to ./data/community_summaries/t20/C3/C3_1.json\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 21...\n",
      "‚úÖ Community Summary already esist for Community 21\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 18...\n",
      "‚úÖ Community Summary already esist for Community 18\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 0...\n",
      "‚úÖ Community Summary already esist for Community 0\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 75...\n",
      "‚ö†Ô∏è Skipping Community 75: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 9...\n",
      "‚úÖ Community Summary already esist for Community 9\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 22...\n",
      "‚úÖ Community Summary already esist for Community 22\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 16...\n",
      "‚úÖ Community Summary already esist for Community 16\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 17...\n",
      "‚úÖ Community Summary already esist for Community 17\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 30...\n",
      "‚ö†Ô∏è Skipping Community 30: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 27...\n",
      "‚ö†Ô∏è Skipping Community 27: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 51...\n",
      "‚ö†Ô∏è Skipping Community 51: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 45...\n",
      "‚ö†Ô∏è Skipping Community 45: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 67...\n",
      "‚ö†Ô∏è Skipping Community 67: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 59...\n",
      "‚ö†Ô∏è Skipping Community 59: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 2...\n",
      "‚úÖ Community Summary already esist for Community 2\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 37...\n",
      "‚úÖ Community Summary already esist for Community 37\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 38...\n",
      "‚ö†Ô∏è Skipping Community 38: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 39...\n",
      "‚úÖ Community Summary already esist for Community 39\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 3...\n",
      "‚ö†Ô∏è Skipping Community 3: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 60...\n",
      "‚úÖ Community Summary already esist for Community 60\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 41...\n",
      "‚ö†Ô∏è Skipping Community 41: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 36...\n",
      "‚ö†Ô∏è Skipping Community 36: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 78...\n",
      "‚ö†Ô∏è Skipping Community 78: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 19...\n",
      "‚ö†Ô∏è Skipping Community 19: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 48...\n",
      "‚úÖ Community Summary already esist for Community 48\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 5...\n",
      "‚úÖ Community Summary already esist for Community 5\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 72...\n",
      "‚ö†Ô∏è Skipping Community 72: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 43...\n",
      "‚ö†Ô∏è Skipping Community 43: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 12...\n",
      "‚ö†Ô∏è Skipping Community 12: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 28...\n",
      "‚ö†Ô∏è Skipping Community 28: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 47...\n",
      "‚ö†Ô∏è Skipping Community 47: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 10...\n",
      "‚úÖ Community Summary already esist for Community 10\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 79...\n",
      "‚úÖ Community Summary already esist for Community 79\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 53...\n",
      "‚ö†Ô∏è Skipping Community 53: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 33...\n",
      "‚ö†Ô∏è Skipping Community 33: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 11...\n",
      "‚ö†Ô∏è Skipping Community 11: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 20...\n",
      "‚úÖ Community Summary already esist for Community 20\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 61...\n",
      "‚ö†Ô∏è Skipping Community 61: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 44...\n",
      "‚úÖ Saved structured summary to ./data/community_summaries/t20/C3/C3_44.json\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 49...\n",
      "‚úÖ Community Summary already esist for Community 49\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 26...\n",
      "‚ö†Ô∏è Skipping Community 26: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 71...\n",
      "‚úÖ Saved structured summary to ./data/community_summaries/t20/C3/C3_71.json\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 65...\n",
      "‚úÖ Community Summary already esist for Community 65\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 29...\n",
      "‚ö†Ô∏è Skipping Community 29: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 66...\n",
      "‚ö†Ô∏è Skipping Community 66: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 24...\n",
      "‚ö†Ô∏è Skipping Community 24: Insufficient data.\n",
      "\n",
      "‚ñ∂ Summarizing C3 Community 25...\n",
      "‚ö†Ô∏è Skipping Community 25: Insufficient data.\n"
     ]
    }
   ],
   "source": [
    "non_useful_communities_ids = create_leaf_level_community_summaries(\n",
    "    kg=kg,\n",
    "    kg_db_name=kg_db_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c77da87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 11, 12, 13, 19, 24, 25, 26, 27, 28, 29, 30, 33, 36, 38, 40, 41, 43, 45, 47, 51, 52, 53, 55, 59, 61, 66, 67, 72, 75, 78]\n"
     ]
    }
   ],
   "source": [
    "non_useful_communities_ids.sort()\n",
    "print(non_useful_communities_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300f4b0",
   "metadata": {},
   "source": [
    "#### High level community summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57742cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.higher_level_community_summaries import HighLevelCommunitySummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd43a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò Processing summaries at level: C2 (27 communities)\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_14.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_27.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_13.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_8.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_11.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_10.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_19.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_18.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_21.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_20.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_17.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_15.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_16.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_28.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_26.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_23.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_22.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_25.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_24.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_7.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_6.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_4.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_5.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_1.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_0.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_3.json\n",
      "‚úÖ Saved high-level summary: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_2.json\n"
     ]
    }
   ],
   "source": [
    "summarizer = HighLevelCommunitySummarizer(\n",
    "    hierarchy=hierarchycal_structure,\n",
    "    summary_root_dir=\"/Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20\",\n",
    "    model=\"o4-mini-2025-04-16\"\n",
    ")\n",
    "\n",
    "summarizer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d21c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò Processing summaries at level: C2 (27 communities)\n",
      "‚è≠Ô∏è Skipping C2_14, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_14.json\n",
      "‚è≠Ô∏è Skipping C2_27, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_27.json\n",
      "‚è≠Ô∏è Skipping C2_13, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_13.json\n",
      "‚è≠Ô∏è Skipping C2_8, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_8.json\n",
      "‚è≠Ô∏è Skipping C2_11, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_11.json\n",
      "‚è≠Ô∏è Skipping C2_10, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_10.json\n",
      "‚è≠Ô∏è Skipping C2_19, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_19.json\n",
      "‚è≠Ô∏è Skipping C2_18, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_18.json\n",
      "‚è≠Ô∏è Skipping C2_21, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_21.json\n",
      "‚è≠Ô∏è Skipping C2_20, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_20.json\n",
      "‚è≠Ô∏è Skipping C2_17, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_17.json\n",
      "‚è≠Ô∏è Skipping C2_15, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_15.json\n",
      "‚è≠Ô∏è Skipping C2_16, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_16.json\n",
      "‚è≠Ô∏è Skipping C2_28, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_28.json\n",
      "‚è≠Ô∏è Skipping C2_26, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_26.json\n",
      "‚è≠Ô∏è Skipping C2_23, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_23.json\n",
      "‚è≠Ô∏è Skipping C2_22, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_22.json\n",
      "‚è≠Ô∏è Skipping C2_25, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_25.json\n",
      "‚è≠Ô∏è Skipping C2_24, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_24.json\n",
      "‚è≠Ô∏è Skipping C2_7, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_7.json\n",
      "‚è≠Ô∏è Skipping C2_6, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_6.json\n",
      "‚è≠Ô∏è Skipping C2_4, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_4.json\n",
      "‚è≠Ô∏è Skipping C2_5, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_5.json\n",
      "‚è≠Ô∏è Skipping C2_1, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_1.json\n",
      "‚è≠Ô∏è Skipping C2_0, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_0.json\n",
      "‚è≠Ô∏è Skipping C2_3, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_3.json\n",
      "‚è≠Ô∏è Skipping C2_2, summary already exists at: /Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2/C2_2.json\n"
     ]
    }
   ],
   "source": [
    "summarizer = HighLevelCommunitySummarizer(\n",
    "    hierarchy=hierarchycal_structure,\n",
    "    summary_root_dir=\"/Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20\",\n",
    "    model=\"o4-mini-2025-04-16\"\n",
    ")\n",
    "\n",
    "summarizer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7552da",
   "metadata": {},
   "source": [
    "#### Test Community Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9070397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.global_query_answerer import GlobalQueryAnswerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79658e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 26 helpful answers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Across the multi‚Äêagent systems literature, one can distill six broad‚Äîand frequently co‚Äêoccurring‚Äîmethodological families.  Within each family sit a variety of concrete algorithms, frameworks and engineering practices.  \\n\\n1. Reinforcement-Learning and Game-Theoretic Approaches  \\n   ‚Ä¢ Multi-agent RL: independent Q-learning, Deep Deterministic Policy Gradient (MADDPG), actor-critic and policy-gradient variants  \\n   ‚Ä¢ Game-theoretic analysis: Nash‚Äêequilibrium computation, fictitious play, strategic bargaining (e.g. Nash-bargaining protocols)  \\n   ‚Ä¢ Tree-search methods: Monte-Carlo Tree Search (MCTS) when agents face combinatorial or game‚Äêlike decision spaces  \\n\\n2. Distributed Optimization and Task-Allocation  \\n   ‚Ä¢ Distributed Constraint Optimization (DCOP) and related message-passing solvers  \\n   ‚Ä¢ Auction- and market-based allocation (incl. Contract Net Protocols)  \\n   ‚Ä¢ Decoupled modular architectures for negotiation (e.g. modular bargaining frameworks)  \\n\\n3. Coordination, Communication and Consensus  \\n   ‚Ä¢ Explicit coordination protocols: negotiation schemes, delegation mechanisms, contract nets  \\n   ‚Ä¢ Consensus and agreement algorithms: flooding, gossip, leader-election, voting schemes  \\n   ‚Ä¢ Multi-Agent Discussion frameworks and ‚ÄúConquer-and-Merge‚Äù styles of iterative consensus  \\n\\n4. Agent-Based Modeling and Simulation  \\n   ‚Ä¢ Agent-Based Modeling (ABM) toolkits for large‚Äêscale simulation design  \\n   ‚Ä¢ Scenario and environment generation driven by structured datasets  \\n   ‚Ä¢ Integration of empirical testing (e.g. drive tests, user‚Äêin‚Äêthe‚Äêloop experiments)  \\n\\n5. LLM-Empowered and Prompt-Based Techniques  \\n   ‚Ä¢ Prompt engineering variants: few-shot/example prompting, chain-of-thought prompting, iterative reflection  \\n   ‚Ä¢ Retrieval-Augmented Generation (RAG) and external memory modules to pull in context at runtime  \\n   ‚Ä¢ Question-Answering and dialogue‚Äêstyle agent APIs built on frozen or fine-tuned pretrained LLMs  \\n   ‚Ä¢ Hybrid workflows that generate or configure ABM/simulation code from LLM outputs  \\n\\n6. System-Engineering and Hybrid Architectures  \\n   ‚Ä¢ Modular, plug-and-play agent components (e.g. ‚Äúprompt agents,‚Äù knowledge-gradient policies, embedded knowledge graphs)  \\n   ‚Ä¢ Model-centric vs. data-centric vs. engineering-centric emphases: from symbolic optimization or gradient-based fine-tuning to data curation and end-to-end system integration  \\n   ‚Ä¢ Soliciting human feedback loops, empirical drive testing or crowd-sourced evaluation to close the design loop  \\n\\nTaken together, most modern multi-agent papers combine one or more algorithms from categories 1‚Äì3, embed them in ABM or empirical testbeds (category 4), and often bolster them with LLM-based scaffolding or prompt-engineering techniques (category 5), all within a carefully engineered software stack (category 6).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3_community_anwer = GlobalQueryAnswerer(\n",
    "    max_tokens= 200000, #TODO check which is the most suitable mac tokesn\n",
    "    summary_dir=\"/Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C3\",\n",
    "    model_name=\"o4-mini-2025-04-16\"\n",
    ")\n",
    "\n",
    "c3_community_anwer.answer_query(\n",
    "    query=\"What are the most commond methods used in papers discussing multi_agent systems\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bb8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Across the multi‚Äêagent systems literature, one can distill six broad‚Äîand frequently co‚Äêoccurring‚Äîmethodological families.  Within each family sit a variety of concrete algorithms, frameworks and engineering practices.  \n",
      "\n",
      "1. Reinforcement-Learning and Game-Theoretic Approaches  \n",
      "   ‚Ä¢ Multi-agent RL: independent Q-learning, Deep Deterministic Policy Gradient (MADDPG), actor-critic and policy-gradient variants  \n",
      "   ‚Ä¢ Game-theoretic analysis: Nash‚Äêequilibrium computation, fictitious play, strategic bargaining (e.g. Nash-bargaining protocols)  \n",
      "   ‚Ä¢ Tree-search methods: Monte-Carlo Tree Search (MCTS) when agents face combinatorial or game‚Äêlike decision spaces  \n",
      "\n",
      "2. Distributed Optimization and Task-Allocation  \n",
      "   ‚Ä¢ Distributed Constraint Optimization (DCOP) and related message-passing solvers  \n",
      "   ‚Ä¢ Auction- and market-based allocation (incl. Contract Net Protocols)  \n",
      "   ‚Ä¢ Decoupled modular architectures for negotiation (e.g. modular bargaining frameworks)  \n",
      "\n",
      "3. Coordination, Communication and Consensus  \n",
      "   ‚Ä¢ Explicit coordination protocols: negotiation schemes, delegation mechanisms, contract nets  \n",
      "   ‚Ä¢ Consensus and agreement algorithms: flooding, gossip, leader-election, voting schemes  \n",
      "   ‚Ä¢ Multi-Agent Discussion frameworks and ‚ÄúConquer-and-Merge‚Äù styles of iterative consensus  \n",
      "\n",
      "4. Agent-Based Modeling and Simulation  \n",
      "   ‚Ä¢ Agent-Based Modeling (ABM) toolkits for large‚Äêscale simulation design  \n",
      "   ‚Ä¢ Scenario and environment generation driven by structured datasets  \n",
      "   ‚Ä¢ Integration of empirical testing (e.g. drive tests, user‚Äêin‚Äêthe‚Äêloop experiments)  \n",
      "\n",
      "5. LLM-Empowered and Prompt-Based Techniques  \n",
      "   ‚Ä¢ Prompt engineering variants: few-shot/example prompting, chain-of-thought prompting, iterative reflection  \n",
      "   ‚Ä¢ Retrieval-Augmented Generation (RAG) and external memory modules to pull in context at runtime  \n",
      "   ‚Ä¢ Question-Answering and dialogue‚Äêstyle agent APIs built on frozen or fine-tuned pretrained LLMs  \n",
      "   ‚Ä¢ Hybrid workflows that generate or configure ABM/simulation code from LLM outputs  \n",
      "\n",
      "6. System-Engineering and Hybrid Architectures  \n",
      "   ‚Ä¢ Modular, plug-and-play agent components (e.g. ‚Äúprompt agents,‚Äù knowledge-gradient policies, embedded knowledge graphs)  \n",
      "   ‚Ä¢ Model-centric vs. data-centric vs. engineering-centric emphases: from symbolic optimization or gradient-based fine-tuning to data curation and end-to-end system integration  \n",
      "   ‚Ä¢ Soliciting human feedback loops, empirical drive testing or crowd-sourced evaluation to close the design loop  \n",
      "\n",
      "Taken together, most modern multi-agent papers combine one or more algorithms from categories 1‚Äì3, embed them in ABM or empirical testbeds (category 4), and often bolster them with LLM-based scaffolding or prompt-engineering techniques (category 5), all within a carefully engineered software stack (category 6).'\n"
     ]
    }
   ],
   "source": [
    "answer= \"'Across the multi‚Äêagent systems literature, one can distill six broad‚Äîand frequently co‚Äêoccurring‚Äîmethodological families.  Within each family sit a variety of concrete algorithms, frameworks and engineering practices.  \\n\\n1. Reinforcement-Learning and Game-Theoretic Approaches  \\n   ‚Ä¢ Multi-agent RL: independent Q-learning, Deep Deterministic Policy Gradient (MADDPG), actor-critic and policy-gradient variants  \\n   ‚Ä¢ Game-theoretic analysis: Nash‚Äêequilibrium computation, fictitious play, strategic bargaining (e.g. Nash-bargaining protocols)  \\n   ‚Ä¢ Tree-search methods: Monte-Carlo Tree Search (MCTS) when agents face combinatorial or game‚Äêlike decision spaces  \\n\\n2. Distributed Optimization and Task-Allocation  \\n   ‚Ä¢ Distributed Constraint Optimization (DCOP) and related message-passing solvers  \\n   ‚Ä¢ Auction- and market-based allocation (incl. Contract Net Protocols)  \\n   ‚Ä¢ Decoupled modular architectures for negotiation (e.g. modular bargaining frameworks)  \\n\\n3. Coordination, Communication and Consensus  \\n   ‚Ä¢ Explicit coordination protocols: negotiation schemes, delegation mechanisms, contract nets  \\n   ‚Ä¢ Consensus and agreement algorithms: flooding, gossip, leader-election, voting schemes  \\n   ‚Ä¢ Multi-Agent Discussion frameworks and ‚ÄúConquer-and-Merge‚Äù styles of iterative consensus  \\n\\n4. Agent-Based Modeling and Simulation  \\n   ‚Ä¢ Agent-Based Modeling (ABM) toolkits for large‚Äêscale simulation design  \\n   ‚Ä¢ Scenario and environment generation driven by structured datasets  \\n   ‚Ä¢ Integration of empirical testing (e.g. drive tests, user‚Äêin‚Äêthe‚Äêloop experiments)  \\n\\n5. LLM-Empowered and Prompt-Based Techniques  \\n   ‚Ä¢ Prompt engineering variants: few-shot/example prompting, chain-of-thought prompting, iterative reflection  \\n   ‚Ä¢ Retrieval-Augmented Generation (RAG) and external memory modules to pull in context at runtime  \\n   ‚Ä¢ Question-Answering and dialogue‚Äêstyle agent APIs built on frozen or fine-tuned pretrained LLMs  \\n   ‚Ä¢ Hybrid workflows that generate or configure ABM/simulation code from LLM outputs  \\n\\n6. System-Engineering and Hybrid Architectures  \\n   ‚Ä¢ Modular, plug-and-play agent components (e.g. ‚Äúprompt agents,‚Äù knowledge-gradient policies, embedded knowledge graphs)  \\n   ‚Ä¢ Model-centric vs. data-centric vs. engineering-centric emphases: from symbolic optimization or gradient-based fine-tuning to data curation and end-to-end system integration  \\n   ‚Ä¢ Soliciting human feedback loops, empirical drive testing or crowd-sourced evaluation to close the design loop  \\n\\nTaken together, most modern multi-agent papers combine one or more algorithms from categories 1‚Äì3, embed them in ABM or empirical testbeds (category 4), and often bolster them with LLM-based scaffolding or prompt-engineering techniques (category 5), all within a carefully engineered software stack (category 6).'\"\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc92ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 23 helpful answers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Across the many communities and papers on multi-agent systems, a handful of methodological families repeatedly surface.  Below is a synthesis of the most commonly employed techniques, organized by broad category:\\n\\n1. Learning-Based Methods  \\n  ‚Ä¢ Multi-Agent Reinforcement Learning (MARL)  \\n    ‚Äì Independent and Centralized Q-Learning, Policy-Gradient and Actor-Critic variants, Multi-Agent DQN  \\n    ‚Äì Hindsight Experience Replay (HER) in multi-agent settings  \\n  ‚Ä¢ Hybrid Neuro-Symbolic & Symbolic Learning  \\n    ‚Äì Symbolic optimizers operating on high-level decision traces  \\n    ‚Äì Gradient-based neural fine-tuning + internal probing of attention patterns  \\n    ‚Äì Self-Evolving Agents using symbolic-rule modules alongside back-propagation  \\n\\n2. Game-Theoretic & Economic Models  \\n  ‚Ä¢ Auction and Bargaining Mechanisms for task allocation  \\n  ‚Ä¢ Nash and Correlated Equilibrium analyses  \\n  ‚Ä¢ Contract-Net Protocols and Negotiation Heuristics  \\n\\n3. Distributed Optimization & Consensus  \\n  ‚Ä¢ ADMM, Gossip- and Consensus-based algorithms for global objective alignment  \\n  ‚Ä¢ Distributed Constraint Optimization Problems (DCOP)  \\n  ‚Ä¢ Combinatorial and Resource-Allocation Workflows (routing, scheduling)  \\n\\n4. Coordination & Communication Schemas  \\n  ‚Ä¢ Modular Architectures (‚ÄúConquer-and-Merge,‚Äù Decoupled Bargaining Modules)  \\n  ‚Ä¢ Delegation Mechanisms: automated task hand-off among specialist agents  \\n  ‚Ä¢ Swarm Intelligence and Bio-Inspired Heuristics (e.g. ant-colony, particle-swarm)  \\n  ‚Ä¢ Emergent Communication Protocols, QA‚ÄêDriven Pipelines for ABM generation  \\n\\n5. Planning, Search & Simulation  \\n  ‚Ä¢ Decentralized Monte Carlo Tree Search (MCTS) and POMDP Solvers  \\n  ‚Ä¢ PDDL-Based Symbolic Planning integrated into agent workflows  \\n  ‚Ä¢ Agent-Based Modeling Platforms (Repast, MASON) for large-scale scenario testing  \\n\\n6. Prompting & LLM-Centric Techniques  \\n  ‚Ä¢ Prompt Engineering Frameworks: in-context learning, chain-of-thought, multi-objective prompts  \\n  ‚Ä¢ Reflection and Self-Evaluation Loops‚Äîagents review and correct their own outputs  \\n  ‚Ä¢ Retrieval-Augmented Generation (RAG) to ground agents in external knowledge during dynamic routing, resource allocation, and fault diagnosis  \\n  ‚Ä¢ QA-Driven or ChatGPT-Style Pipelines, including feedback-driven reprompting and tool-calling agents  \\n\\n7. Novel Cooperative Architectures  \\n  ‚Ä¢ Cooperative Multi-Agent Systems with specialized LLM agents (e.g. separate modules for geography, coverage optimization, cost trade-offs)  \\n  ‚Ä¢ PromptAgentMethod: trial-and-error exploration, error feedback loops, Monte Carlo search for prompt optimization  \\n  ‚Ä¢ ‚ÄúCompanion‚Äù and ‚ÄúMood‚Äù systems modeling narrative assistance and emotional state tracking across conversational agents  \\n\\nTaken together, these methods are often combined‚Äîfor example, a MARL framework may employ RAG for rich observations, invoke auction protocols for resource negotiation, and leverage prompt-engineering heuristics for reasoning chains‚Äîyielding robust, flexible multi-agent solutions in domains from network optimization to narrative generation.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_community_anwer = GlobalQueryAnswerer(\n",
    "    max_tokens= 200000, #TODO check which is the most suitable mac tokesn\n",
    "    summary_dir=\"/Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2\",\n",
    "    model_name=\"o4-mini-2025-04-16\"\n",
    ")\n",
    "\n",
    "\n",
    "c2_community_anwer.answer_query(\n",
    "    query=\"What are the most commond methods used in papers discussing multi_agent systems\",\n",
    ")\n",
    "# 2m 21.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268219dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Across the many communities and papers on multi-agent systems, a handful of methodological families repeatedly surface.  Below is a synthesis of the most commonly employed techniques, organized by broad category:\n",
      "\n",
      "1. Learning-Based Methods  \n",
      "  ‚Ä¢ Multi-Agent Reinforcement Learning (MARL)  \n",
      "    ‚Äì Independent and Centralized Q-Learning, Policy-Gradient and Actor-Critic variants, Multi-Agent DQN  \n",
      "    ‚Äì Hindsight Experience Replay (HER) in multi-agent settings  \n",
      "  ‚Ä¢ Hybrid Neuro-Symbolic & Symbolic Learning  \n",
      "    ‚Äì Symbolic optimizers operating on high-level decision traces  \n",
      "    ‚Äì Gradient-based neural fine-tuning + internal probing of attention patterns  \n",
      "    ‚Äì Self-Evolving Agents using symbolic-rule modules alongside back-propagation  \n",
      "\n",
      "2. Game-Theoretic & Economic Models  \n",
      "  ‚Ä¢ Auction and Bargaining Mechanisms for task allocation  \n",
      "  ‚Ä¢ Nash and Correlated Equilibrium analyses  \n",
      "  ‚Ä¢ Contract-Net Protocols and Negotiation Heuristics  \n",
      "\n",
      "3. Distributed Optimization & Consensus  \n",
      "  ‚Ä¢ ADMM, Gossip- and Consensus-based algorithms for global objective alignment  \n",
      "  ‚Ä¢ Distributed Constraint Optimization Problems (DCOP)  \n",
      "  ‚Ä¢ Combinatorial and Resource-Allocation Workflows (routing, scheduling)  \n",
      "\n",
      "4. Coordination & Communication Schemas  \n",
      "  ‚Ä¢ Modular Architectures (‚ÄúConquer-and-Merge,‚Äù Decoupled Bargaining Modules)  \n",
      "  ‚Ä¢ Delegation Mechanisms: automated task hand-off among specialist agents  \n",
      "  ‚Ä¢ Swarm Intelligence and Bio-Inspired Heuristics (e.g. ant-colony, particle-swarm)  \n",
      "  ‚Ä¢ Emergent Communication Protocols, QA‚ÄêDriven Pipelines for ABM generation  \n",
      "\n",
      "5. Planning, Search & Simulation  \n",
      "  ‚Ä¢ Decentralized Monte Carlo Tree Search (MCTS) and POMDP Solvers  \n",
      "  ‚Ä¢ PDDL-Based Symbolic Planning integrated into agent workflows  \n",
      "  ‚Ä¢ Agent-Based Modeling Platforms (Repast, MASON) for large-scale scenario testing  \n",
      "\n",
      "6. Prompting & LLM-Centric Techniques  \n",
      "  ‚Ä¢ Prompt Engineering Frameworks: in-context learning, chain-of-thought, multi-objective prompts  \n",
      "  ‚Ä¢ Reflection and Self-Evaluation Loops‚Äîagents review and correct their own outputs  \n",
      "  ‚Ä¢ Retrieval-Augmented Generation (RAG) to ground agents in external knowledge during dynamic routing, resource allocation, and fault diagnosis  \n",
      "  ‚Ä¢ QA-Driven or ChatGPT-Style Pipelines, including feedback-driven reprompting and tool-calling agents  \n",
      "\n",
      "7. Novel Cooperative Architectures  \n",
      "  ‚Ä¢ Cooperative Multi-Agent Systems with specialized LLM agents (e.g. separate modules for geography, coverage optimization, cost trade-offs)  \n",
      "  ‚Ä¢ PromptAgentMethod: trial-and-error exploration, error feedback loops, Monte Carlo search for prompt optimization  \n",
      "  ‚Ä¢ ‚ÄúCompanion‚Äù and ‚ÄúMood‚Äù systems modeling narrative assistance and emotional state tracking across conversational agents  \n",
      "\n",
      "Taken together, these methods are often combined‚Äîfor example, a MARL framework may employ RAG for rich observations, invoke auction protocols for resource negotiation, and leverage prompt-engineering heuristics for reasoning chains‚Äîyielding robust, flexible multi-agent solutions in domains from network optimization to narrative generation.'\n"
     ]
    }
   ],
   "source": [
    "c2_answer = \"'Across the many communities and papers on multi-agent systems, a handful of methodological families repeatedly surface.  Below is a synthesis of the most commonly employed techniques, organized by broad category:\\n\\n1. Learning-Based Methods  \\n  ‚Ä¢ Multi-Agent Reinforcement Learning (MARL)  \\n    ‚Äì Independent and Centralized Q-Learning, Policy-Gradient and Actor-Critic variants, Multi-Agent DQN  \\n    ‚Äì Hindsight Experience Replay (HER) in multi-agent settings  \\n  ‚Ä¢ Hybrid Neuro-Symbolic & Symbolic Learning  \\n    ‚Äì Symbolic optimizers operating on high-level decision traces  \\n    ‚Äì Gradient-based neural fine-tuning + internal probing of attention patterns  \\n    ‚Äì Self-Evolving Agents using symbolic-rule modules alongside back-propagation  \\n\\n2. Game-Theoretic & Economic Models  \\n  ‚Ä¢ Auction and Bargaining Mechanisms for task allocation  \\n  ‚Ä¢ Nash and Correlated Equilibrium analyses  \\n  ‚Ä¢ Contract-Net Protocols and Negotiation Heuristics  \\n\\n3. Distributed Optimization & Consensus  \\n  ‚Ä¢ ADMM, Gossip- and Consensus-based algorithms for global objective alignment  \\n  ‚Ä¢ Distributed Constraint Optimization Problems (DCOP)  \\n  ‚Ä¢ Combinatorial and Resource-Allocation Workflows (routing, scheduling)  \\n\\n4. Coordination & Communication Schemas  \\n  ‚Ä¢ Modular Architectures (‚ÄúConquer-and-Merge,‚Äù Decoupled Bargaining Modules)  \\n  ‚Ä¢ Delegation Mechanisms: automated task hand-off among specialist agents  \\n  ‚Ä¢ Swarm Intelligence and Bio-Inspired Heuristics (e.g. ant-colony, particle-swarm)  \\n  ‚Ä¢ Emergent Communication Protocols, QA‚ÄêDriven Pipelines for ABM generation  \\n\\n5. Planning, Search & Simulation  \\n  ‚Ä¢ Decentralized Monte Carlo Tree Search (MCTS) and POMDP Solvers  \\n  ‚Ä¢ PDDL-Based Symbolic Planning integrated into agent workflows  \\n  ‚Ä¢ Agent-Based Modeling Platforms (Repast, MASON) for large-scale scenario testing  \\n\\n6. Prompting & LLM-Centric Techniques  \\n  ‚Ä¢ Prompt Engineering Frameworks: in-context learning, chain-of-thought, multi-objective prompts  \\n  ‚Ä¢ Reflection and Self-Evaluation Loops‚Äîagents review and correct their own outputs  \\n  ‚Ä¢ Retrieval-Augmented Generation (RAG) to ground agents in external knowledge during dynamic routing, resource allocation, and fault diagnosis  \\n  ‚Ä¢ QA-Driven or ChatGPT-Style Pipelines, including feedback-driven reprompting and tool-calling agents  \\n\\n7. Novel Cooperative Architectures  \\n  ‚Ä¢ Cooperative Multi-Agent Systems with specialized LLM agents (e.g. separate modules for geography, coverage optimization, cost trade-offs)  \\n  ‚Ä¢ PromptAgentMethod: trial-and-error exploration, error feedback loops, Monte Carlo search for prompt optimization  \\n  ‚Ä¢ ‚ÄúCompanion‚Äù and ‚ÄúMood‚Äù systems modeling narrative assistance and emotional state tracking across conversational agents  \\n\\nTaken together, these methods are often combined‚Äîfor example, a MARL framework may employ RAG for rich observations, invoke auction protocols for resource negotiation, and leverage prompt-engineering heuristics for reasoning chains‚Äîyielding robust, flexible multi-agent solutions in domains from network optimization to narrative generation.'\"\n",
    "\n",
    "print(c2_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993684bd",
   "metadata": {},
   "source": [
    "#### same execution but with parallel and prompts updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd830a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 20 helpful answers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Common Methods in Multi-Agent Systems Research\\n\\nSynthesizing insights across multiple analyst reports, we identify six principal families of methods employed in multi-agent systems (MAS) papers. Each reflects distinct goals‚Äîranging from prompt coordination and optimization loops to architectural patterns and domain-specific systems.\\n\\n---\\n\\n## 1. Prompt Engineering & In-Context Learning  \\nRigorously defines how agents generate, structure, and share prompts to coordinate actions.  \\n- **Formal Prompt Engineering Framework**: Specifies prompt spaces, constraints, and coordination objectives.  \\n- **Multi-Objective Directional Prompting**: Guides each agent toward goals (e.g., accuracy, style) via directional vectors in prompt space.  \\n- **Dynamic Prompt Assembly**: Constructs modular ‚Äúsub-agent‚Äù prompts at inference time based on feedback and roles.  \\n(Data: 7, 14, 117)\\n\\n## 2. Chain-of-Thought Reasoning & Reflection  \\nStructures complex decision processes and self-evaluation across collaborating agents.  \\n- **Chain-of-Thought**: Decomposes tasks into step-by-step reasoning shared among agents.  \\n- **Reflection Loops**: Agents critique their own or peers‚Äô outputs to refine subsequent iterations.  \\n(Data: 14, 117)\\n\\n## 3. Coordination & Delegation Mechanisms  \\nFocuses on how agents distribute tasks, resolve conflicts, and maintain coherent collaboration.  \\n- **Multi-Agent Discussion & Bargaining**: Modular architectures that negotiate responsibilities in negotiation settings.  \\n- **Delegation Mechanisms**: Task- or responsibility-delegation techniques tightly coupled with system design principles.  \\n(Data: 70, 78, 71)\\n\\n## 4. Feedback-Driven Optimization  \\nEmploys iterative loops‚Äîboth automated and human-in-the-loop‚Äîto refine agent performance.  \\n- **Trial-and-Error Exploration**: Iteratively tests prompt/agent variants to identify high-performing patterns.  \\n- **Error Feedback**: Uses model responses or crowd-sourced reports to generate corrective signals.  \\n- **Feedback-Driven Reprompting**: Automated critique loops where agents refine each other‚Äôs outputs via targeted re-prompts.  \\n(Data: 1, 7, 160)\\n\\n## 5. Architectural Patterns & Tool Integration  \\nDefines structural blueprints and external tool calls to extend agent capabilities.  \\n- **Cooperative Multi-Agent Teams**: Specialized agents (e.g., geographic data vs. cost optimization) collaborating for robustness.  \\n- **Tool-Calling Agents**: Embeds calls to external services (databases, calculators) within prompts to share context.  \\n- **QA-Driven ABM Pipelines**: Automated generation of agent-based models via question-answering loops.  \\n(Data: 163, 164, 14, 78)\\n\\n## 6. Domain-Specific Systems (Narrative & Simulation)  \\nApplies MAS methods to specialized domains such as storytelling or field validation.  \\n- **Companion Development**: LLM ‚Äúcompanions‚Äù that suggest narrative twists and maintain character consistency.  \\n- **Mood Systems**: Sentiment-tracking architectures to adapt agents‚Äô tone and emotional state over time.  \\n- **Inter-Agent Protocols**: Centralized vs. decentralized control, communication protocols, and conflict-resolution in simulated environments.  \\n(Data: 191, 192, 188)\\n\\n---\\n\\n**Implications:**  \\nBy combining these methods, researchers can design MAS that balance individual agent autonomy with global coherence, continuously refine performance via feedback loops, and leverage specialized architectures for domain-specific tasks. Continuous integration of prompt engineering, systematic feedback, and robust coordination protocols remains at the forefront of MAS innovation.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_community_anwer = GlobalQueryAnswerer(\n",
    "    max_tokens= 200000, #TODO check which is the most suitable mac tokesn\n",
    "    summary_dir=\"/Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2\",\n",
    "    model_name=\"o4-mini-2025-04-16\"\n",
    ")\n",
    "\n",
    "\n",
    "c2_community_anwer.answer_query(\n",
    "    query=\"What are the most commond methods used in papers discussing multi_agent systems\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6888b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'# Common Methods in Multi-Agent Systems Research\n",
      "\n",
      "Synthesizing insights across multiple analyst reports, we identify six principal families of methods employed in multi-agent systems (MAS) papers. Each reflects distinct goals‚Äîranging from prompt coordination and optimization loops to architectural patterns and domain-specific systems.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Prompt Engineering & In-Context Learning  \n",
      "Rigorously defines how agents generate, structure, and share prompts to coordinate actions.  \n",
      "- **Formal Prompt Engineering Framework**: Specifies prompt spaces, constraints, and coordination objectives.  \n",
      "- **Multi-Objective Directional Prompting**: Guides each agent toward goals (e.g., accuracy, style) via directional vectors in prompt space.  \n",
      "- **Dynamic Prompt Assembly**: Constructs modular ‚Äúsub-agent‚Äù prompts at inference time based on feedback and roles.  \n",
      "(Data: 7, 14, 117)\n",
      "\n",
      "## 2. Chain-of-Thought Reasoning & Reflection  \n",
      "Structures complex decision processes and self-evaluation across collaborating agents.  \n",
      "- **Chain-of-Thought**: Decomposes tasks into step-by-step reasoning shared among agents.  \n",
      "- **Reflection Loops**: Agents critique their own or peers‚Äô outputs to refine subsequent iterations.  \n",
      "(Data: 14, 117)\n",
      "\n",
      "## 3. Coordination & Delegation Mechanisms  \n",
      "Focuses on how agents distribute tasks, resolve conflicts, and maintain coherent collaboration.  \n",
      "- **Multi-Agent Discussion & Bargaining**: Modular architectures that negotiate responsibilities in negotiation settings.  \n",
      "- **Delegation Mechanisms**: Task- or responsibility-delegation techniques tightly coupled with system design principles.  \n",
      "(Data: 70, 78, 71)\n",
      "\n",
      "## 4. Feedback-Driven Optimization  \n",
      "Employs iterative loops‚Äîboth automated and human-in-the-loop‚Äîto refine agent performance.  \n",
      "- **Trial-and-Error Exploration**: Iteratively tests prompt/agent variants to identify high-performing patterns.  \n",
      "- **Error Feedback**: Uses model responses or crowd-sourced reports to generate corrective signals.  \n",
      "- **Feedback-Driven Reprompting**: Automated critique loops where agents refine each other‚Äôs outputs via targeted re-prompts.  \n",
      "(Data: 1, 7, 160)\n",
      "\n",
      "## 5. Architectural Patterns & Tool Integration  \n",
      "Defines structural blueprints and external tool calls to extend agent capabilities.  \n",
      "- **Cooperative Multi-Agent Teams**: Specialized agents (e.g., geographic data vs. cost optimization) collaborating for robustness.  \n",
      "- **Tool-Calling Agents**: Embeds calls to external services (databases, calculators) within prompts to share context.  \n",
      "- **QA-Driven ABM Pipelines**: Automated generation of agent-based models via question-answering loops.  \n",
      "(Data: 163, 164, 14, 78)\n",
      "\n",
      "## 6. Domain-Specific Systems (Narrative & Simulation)  \n",
      "Applies MAS methods to specialized domains such as storytelling or field validation.  \n",
      "- **Companion Development**: LLM ‚Äúcompanions‚Äù that suggest narrative twists and maintain character consistency.  \n",
      "- **Mood Systems**: Sentiment-tracking architectures to adapt agents‚Äô tone and emotional state over time.  \n",
      "- **Inter-Agent Protocols**: Centralized vs. decentralized control, communication protocols, and conflict-resolution in simulated environments.  \n",
      "(Data: 191, 192, 188)\n",
      "\n",
      "---\n",
      "\n",
      "**Implications:**  \n",
      "By combining these methods, researchers can design MAS that balance individual agent autonomy with global coherence, continuously refine performance via feedback loops, and leverage specialized architectures for domain-specific tasks. Continuous integration of prompt engineering, systematic feedback, and robust coordination protocols remains at the forefront of MAS innovation.'\n"
     ]
    }
   ],
   "source": [
    "print(\"'# Common Methods in Multi-Agent Systems Research\\n\\nSynthesizing insights across multiple analyst reports, we identify six principal families of methods employed in multi-agent systems (MAS) papers. Each reflects distinct goals‚Äîranging from prompt coordination and optimization loops to architectural patterns and domain-specific systems.\\n\\n---\\n\\n## 1. Prompt Engineering & In-Context Learning  \\nRigorously defines how agents generate, structure, and share prompts to coordinate actions.  \\n- **Formal Prompt Engineering Framework**: Specifies prompt spaces, constraints, and coordination objectives.  \\n- **Multi-Objective Directional Prompting**: Guides each agent toward goals (e.g., accuracy, style) via directional vectors in prompt space.  \\n- **Dynamic Prompt Assembly**: Constructs modular ‚Äúsub-agent‚Äù prompts at inference time based on feedback and roles.  \\n(Data: 7, 14, 117)\\n\\n## 2. Chain-of-Thought Reasoning & Reflection  \\nStructures complex decision processes and self-evaluation across collaborating agents.  \\n- **Chain-of-Thought**: Decomposes tasks into step-by-step reasoning shared among agents.  \\n- **Reflection Loops**: Agents critique their own or peers‚Äô outputs to refine subsequent iterations.  \\n(Data: 14, 117)\\n\\n## 3. Coordination & Delegation Mechanisms  \\nFocuses on how agents distribute tasks, resolve conflicts, and maintain coherent collaboration.  \\n- **Multi-Agent Discussion & Bargaining**: Modular architectures that negotiate responsibilities in negotiation settings.  \\n- **Delegation Mechanisms**: Task- or responsibility-delegation techniques tightly coupled with system design principles.  \\n(Data: 70, 78, 71)\\n\\n## 4. Feedback-Driven Optimization  \\nEmploys iterative loops‚Äîboth automated and human-in-the-loop‚Äîto refine agent performance.  \\n- **Trial-and-Error Exploration**: Iteratively tests prompt/agent variants to identify high-performing patterns.  \\n- **Error Feedback**: Uses model responses or crowd-sourced reports to generate corrective signals.  \\n- **Feedback-Driven Reprompting**: Automated critique loops where agents refine each other‚Äôs outputs via targeted re-prompts.  \\n(Data: 1, 7, 160)\\n\\n## 5. Architectural Patterns & Tool Integration  \\nDefines structural blueprints and external tool calls to extend agent capabilities.  \\n- **Cooperative Multi-Agent Teams**: Specialized agents (e.g., geographic data vs. cost optimization) collaborating for robustness.  \\n- **Tool-Calling Agents**: Embeds calls to external services (databases, calculators) within prompts to share context.  \\n- **QA-Driven ABM Pipelines**: Automated generation of agent-based models via question-answering loops.  \\n(Data: 163, 164, 14, 78)\\n\\n## 6. Domain-Specific Systems (Narrative & Simulation)  \\nApplies MAS methods to specialized domains such as storytelling or field validation.  \\n- **Companion Development**: LLM ‚Äúcompanions‚Äù that suggest narrative twists and maintain character consistency.  \\n- **Mood Systems**: Sentiment-tracking architectures to adapt agents‚Äô tone and emotional state over time.  \\n- **Inter-Agent Protocols**: Centralized vs. decentralized control, communication protocols, and conflict-resolution in simulated environments.  \\n(Data: 191, 192, 188)\\n\\n---\\n\\n**Implications:**  \\nBy combining these methods, researchers can design MAS that balance individual agent autonomy with global coherence, continuously refine performance via feedback loops, and leverage specialized architectures for domain-specific tasks. Continuous integration of prompt engineering, systematic feedback, and robust coordination protocols remains at the forefront of MAS innovation.'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6d1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e72e2202",
   "metadata": {},
   "source": [
    "#### Global question generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22dab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.global_question_generator import GlobalQuestionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d96fe4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting global question generation...\n",
      "üì¶ Target: 2 personas √ó 2 tasks √ó 2 questions = 8 total questions\n",
      "\n",
      "üë§ Generating tasks for Persona 1/2...\n",
      "   üìå Generating 2 questions for Task 1/2...\n",
      "     ‚úÖ Progress: 2/8 questions generated\n",
      "\n",
      "üë§ Generating tasks for Persona 2/2...\n",
      "   üìå Generating 2 questions for Task 1/2...\n",
      "     ‚úÖ Progress: 4/8 questions generated\n",
      "   üìå Generating 2 questions for Task 2/2...\n",
      "     ‚úÖ Progress: 6/8 questions generated\n",
      "\n",
      "üíæ Saving generated questions...\n",
      "‚úÖ Saved 3 persona-task blocks to ./data/global_questions/t20/global_sensemaking_questions.json\n",
      "‚úÖ All questions saved successfully.\n"
     ]
    }
   ],
   "source": [
    "corpus_description = \"\"\" \n",
    "This corpus contains 20 recent research papers retrieved from arXiv using the query: \"agent OR large language model OR prompt engineering\". The papers focus on cutting-edge advancements in large language models (LLMs), intelligent agent architectures, and prompt engineering strategies to enhance model reasoning and coordination. Key areas include:\n",
    "\n",
    "- Design of multi-agent systems using LLMs as agents or controllers.\n",
    "- Prompting techniques such as Chain-of-Thought, Reflection, and ReAct used for structured reasoning.\n",
    "- Methods for orchestrating collaborative agents in planning, execution, or communication tasks.\n",
    "- Evaluation of LLM interpretability, alignment with human intent, and safe deployment in dynamic environments.\n",
    "- Societal impacts, including ethical considerations, safety risks, and governance frameworks for autonomous LLM-based systems.\n",
    "\n",
    "The corpus spans technical proposals, system frameworks, empirical evaluations, and conceptual discussions relevant to both applied NLP and AI safety domains.\n",
    "\"\"\"\n",
    "\n",
    "generator = GlobalQuestionGenerator(\n",
    "    model=\"o4-mini-2025-04-16\",\n",
    "    output_path=\"./data/global_questions/t20\"\n",
    ")\n",
    "\n",
    "questions = generator.run(\n",
    "    corpus_description=corpus_description,\n",
    "    k=2,\n",
    "    n=2,\n",
    "    m=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9290720",
   "metadata": {},
   "source": [
    "#### Sensemaking avaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eed319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.0 at grpc_health/v1/health.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/aggregate.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/base.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/base_search.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/batch.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/batch_delete.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/search_get.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/generative.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/properties.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.0 at v1/tenants.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n"
     ]
    }
   ],
   "source": [
    "from src.sensemaking_evaluator import SensemakingEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7adf5be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milvus DB exists. Connecting to existing database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/milvus_lite/__init__.py:15: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating Q1/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 27 helpful answers.\n",
      "üîç Evaluating Q2/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 27 helpful answers.\n",
      "üîç Evaluating Q3/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 27 helpful answers.\n",
      "üîç Evaluating Q4/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 23 helpful answers.\n",
      "üîç Evaluating Q5/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 29 helpful answers.\n",
      "üîç Evaluating Q6/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 25 helpful answers.\n",
      "üîç Evaluating Q7/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 29 helpful answers.\n",
      "üîç Evaluating Q8/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 22 helpful answers.\n",
      "üîç Evaluating Q9/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 28 helpful answers.\n",
      "üîç Evaluating Q10/10\n",
      "üß© Prepared 30 summary chunks.\n",
      "‚úÖ Collected 29 helpful answers.\n",
      "\n",
      "‚úÖ All evaluations saved to: ./data/global_questions/t20/C3_evaluated_answers.md\n"
     ]
    }
   ],
   "source": [
    "from src.rag_pipeline import RAGPipeline\n",
    "\n",
    "config = {\n",
    "    \"mode\": \"load\",\n",
    "    \"kg_db_name\": \"t20\",\n",
    "    \"summary_dir\": \"/Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C3\",\n",
    "}\n",
    "\n",
    "pipeline = RAGPipeline(config=config)\n",
    "pipeline.initialize()\n",
    "\n",
    "evaluator = SensemakingEvaluator(\n",
    "    question_path=\"./data/global_questions/t20/global_sensemaking_questions.json\",\n",
    "    output_path=\"./data/global_questions/t20/C3_evaluated_answers.md\",\n",
    "    rag_pipeline=pipeline,\n",
    "    eval_model=\"o4-mini-2025-04-16\"\n",
    ")\n",
    "\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59c3e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milvus DB exists. Connecting to existing database...\n",
      "üîç Evaluating Q1/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 25 helpful answers.\n",
      "üîç Evaluating Q2/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 23 helpful answers.\n",
      "üîç Evaluating Q3/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 24 helpful answers.\n",
      "üîç Evaluating Q4/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 24 helpful answers.\n",
      "üîç Evaluating Q5/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 25 helpful answers.\n",
      "üîç Evaluating Q6/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 22 helpful answers.\n",
      "üîç Evaluating Q7/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 24 helpful answers.\n",
      "üîç Evaluating Q8/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 20 helpful answers.\n",
      "üîç Evaluating Q9/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 25 helpful answers.\n",
      "üîç Evaluating Q10/10\n",
      "üß© Prepared 27 summary chunks.\n",
      "‚úÖ Collected 24 helpful answers.\n",
      "\n",
      "‚úÖ All evaluations saved to: ./data/global_questions/t20/C2_evaluated_answers.md\n"
     ]
    }
   ],
   "source": [
    "from src.rag_pipeline import RAGPipeline\n",
    "\n",
    "config = {\n",
    "    \"mode\": \"load\",\n",
    "    \"kg_db_name\": \"t20\",\n",
    "    \"summary_dir\": \"/Users/danielguarnizo/workspace/Master/LLMs/GraphRAG/data/community_summaries/t20/C2\",\n",
    "}\n",
    "\n",
    "pipeline = RAGPipeline(config=config)\n",
    "pipeline.initialize()\n",
    "\n",
    "evaluator = SensemakingEvaluator(\n",
    "    question_path=\"./data/global_questions/t20/global_sensemaking_questions.json\",\n",
    "    output_path=\"./data/global_questions/t20/C2_evaluated_answers.md\",\n",
    "    rag_pipeline=pipeline,\n",
    "    eval_model=\"o4-mini-2025-04-16\"\n",
    ")\n",
    "\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19bbed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
